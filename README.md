# EXP-2 – PROMPT ENGINEERING
```
Name: Soundariyan MN
Reg No: 212222230146
```

## Aim
To conduct a comparative analysis of different types of prompting patterns and explain them with various test scenarios.  
The experiment demonstrates how broad/unstructured prompts differ from basic/clearer prompts in terms of response quality, accuracy, and depth.

---

## Algorithm

1. Identify Prompting Patterns:  
   - Broad / Unstructured prompts  
   - Refined / Clear prompts  
   - Advanced prompting techniques (Chain-of-Thought, Few-shot, Role-based prompts)  

2. Design Test Scenarios:  
   - General Knowledge (Fact-based Q&A)  
   - Creative Task (Story/Poem generation)  
   - Problem Solving (Math/Logic)  
   - Instruction Following (Step-wise process)  

3. Test Responses:  
   - Feed different prompts (broad vs refined) into the model  
   - Record the generated responses  

4. Compare Quality:  
   - Accuracy  
   - Depth of explanation  
   - Relevance to the prompt  

5. Analyze Findings:  
   - Highlight which prompting pattern yields better responses  
   - Note strengths/weaknesses of each style  

![Prompt Engineering Patterns](https://github.com/barathsubramani/EXPERIMENT-2-PROMPT-ENGINEERING/blob/main/Gemini_Generated_Image_psdcqzpsdcqzpsdc.png)
---

## Output

### Scenario 1 – General Knowledge
- **Broad Prompt:** "Tell me about space."  
  - Response: Very generic, surface-level details about planets and stars.  
- **Refined Prompt:** "Explain how black holes are formed in simple terms for a 10-year-old."  
  - Response: Clear, structured explanation with analogy, suitable for a child.  

**Observation:** Refined prompt gives more useful and context-aware responses.  



---

### Scenario 2 – Creative Task
- **Broad Prompt:** "Write a story."  
  - Response: Short, vague story with limited details.  
- **Refined Prompt:** "Write a short story about a time-traveling scientist who fixes historical mistakes."  
  - Response: Rich, imaginative narrative with detailed characters and plot.  

**Observation:** Refined prompt produces more engaging and controlled creativity.  



---

### Scenario 3 – Problem Solving
- **Broad Prompt:** "Solve math."  
  - Response: No clear direction, response may be random.  
- **Refined Prompt:** "Solve: If a train travels at 60 km/h for 2.5 hours, how far does it go?"  
  - Response: Correctly calculates distance = 150 km with explanation.  

**Observation:** Precise prompts guide the model to produce accurate solutions.  



---

### Scenario 4 – Instruction Following
- **Broad Prompt:** "Explain photosynthesis."  
  - Response: General explanation.  
- **Refined Prompt:** "Explain photosynthesis step by step, using bullet points, suitable for a biology exam."  
  - Response: Detailed, structured points (light absorption → glucose production → oxygen release).  

**Observation:** Structured prompts result in exam-ready, well-formatted answers.  



---

## Result
- Broad/unstructured prompts generate vague and generic answers.  
- Clear and refined prompts yield more accurate, structured, and context-aware responses.  
- Advanced prompting techniques (role-based, few-shot, chain-of-thought) significantly improve reasoning and creativity.  
- **Conclusion:** The effectiveness of LLMs depends strongly on prompt engineering, and refined prompting is essential for quality outputs.  

